# EquiSense AI - Enterprise Stock Research Platform

**ðŸš€ Production-ready AI-powered stock research platform with 12 completed competitive initiatives. Features comprehensive analysis for Indian and global markets with advanced data federation, real-time monitoring, and enterprise-grade security.**

## âœ… **ALL INITIATIVES COMPLETED (12/12)**
- **Indian Market Data Excellence** - Multi-source data federation
- **Regulatory Filing Analysis** - SEC Edgar & BSE/NSE integration  
- **Portfolio & Dashboard Management** - Complete portfolio system
- **Multi-LLM Intelligence System** - LLM routing and validation
- **Earnings Call & Transcript Analysis** - Sentiment and guidance extraction
- **Insider Trading & Ownership Tracking** - SEC Form 4 & 13F integration
- **Comprehensive Backtesting Framework** - Performance tracking and analysis
- **API & Automation Layer** - Complete REST API with authentication
- **Real-time Monitoring & Alerts** - Event detection and notifications
- **Advanced Visualization & Reporting** - PDF generation and export capabilities
- **Security & Compliance** - OAuth2, encryption, audit logging
- **Performance Optimization** - Monitoring, caching, and optimization

## ðŸ“Š **Key Features**
- **ðŸ‡®ðŸ‡³ India-First**: Default to Indian markets with RELIANCE ticker
- **ðŸ“ˆ 90%+ DCF Success Rate**: Robust valuation modeling
- **ðŸ”„ Real-Time Performance**: Health scoring and monitoring
- **ðŸ”’ Enterprise Security**: JWT authentication and role-based access
- **ðŸ“Š Rich Analysis**: 5-pillar scoring, technical analysis, sentiment analysis
- **ðŸŒ Multi-Market**: Support for US, UK, Canada markets

## ðŸš€ Quick Start

### Prerequisites
- Python 3.11+ 
- Node.js 18+
- [Ollama](https://ollama.com/) installed and running
- Docker (optional, for Langfuse observability)

---

## ðŸ“¦ One-Time Setup

### 1. Backend Setup
```bash
# Navigate to project root (replace with your actual path)
cd /path/to/your/EquiSense_AI

# Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Upgrade pip and install dependencies
pip install -U pip setuptools wheel
pip install -e '.[dev]'

# Install browser dependencies for potential web scraping
python -m playwright install --with-deps chromium
```

### 1.1 Optional: Financial NLP (Temporarily disabled)
Financial-domain Transformer integration is currently disabled. We'll re-introduce a configurable NLP model after evaluation.

### 2. Frontend Setup
```bash
# Navigate to frontend directory (from project root)
cd agentic-stock-research/frontend

# Install dependencies
npm ci

# Create environment file
echo "VITE_API_BASE_URL=http://localhost:8000" > .env
```

### 3. AI Model Setup
```bash
# Install Ollama model (if not already installed)
ollama pull gemma3:4b

# Verify model is available
ollama list | grep gemma3
```

### 4. Optional: Langfuse Observability Setup
```bash
# Return to project root first
cd ../../

# Start Langfuse (Docker required)
docker compose -f docker-compose.langfuse.yml up -d

# Create backend .env file with Langfuse settings
cat > agentic-stock-research/.env << EOF
LANGFUSE_PUBLIC_KEY=your_public_key
LANGFUSE_SECRET_KEY=your_secret_key
LANGFUSE_HOST=http://localhost:3100
EOF
```

---

## ðŸƒâ€â™‚ï¸ Running the Services

### Method 1: Quick Start Script (Recommended)
```bash
# From project root, run everything with one command
./scripts/dev.sh

# To check if services are running
./scripts/pids.sh
```

### Method 2: Manual Service Startup

#### Start Backend
```bash
# From project root
source .venv/bin/activate
export PYTHONPATH="$PWD/agentic-stock-research"

# Start backend (foreground)
python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# Or run in background
python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload &
```

#### Start Frontend
```bash
# From project root, navigate to frontend
cd agentic-stock-research/frontend

# Start frontend (foreground)
npm run dev

# Or run in background
npm run dev &
```

#### Start Ollama (if not running)
```bash
# Start Ollama service
ollama serve &

# Load the model
ollama run gemma3:4b
```

### Method 3: Docker (Everything)
```bash
# Build and run all services
docker compose up --build

# Or run in background
docker compose up --build -d
```

---

## ðŸŒ Access Points

Once all services are running:

- **ðŸŽ¯ Main Application**: http://localhost:5173 (Frontend)
- **ðŸ”§ Backend API**: http://localhost:8000 (FastAPI + Auto Docs)
- **ðŸ“Š API Documentation**: http://localhost:8000/docs
- **ðŸ” Health Check**: http://localhost:8000/health
- **ðŸ“ˆ Langfuse Dashboard**: http://localhost:3100 (if enabled)

## ðŸ†• **New API Endpoints (All Initiatives)**

### **Performance & Monitoring**
- `GET /api/v1/performance/health` - Performance system health
- `GET /api/v1/performance/metrics` - Real-time performance metrics
- `POST /api/v1/performance/optimize` - Run optimization routines

### **Authentication & Security**
- `POST /api/v1/auth/login` - User authentication
- `POST /api/v1/auth/register` - User registration
- `POST /api/v1/auth/refresh` - Token refresh

### **Portfolio Management**
- `GET /api/v1/portfolio` - Get user portfolios
- `POST /api/v1/portfolio` - Create/update portfolio
- `GET /api/v1/portfolio/{id}/performance` - Portfolio analytics

### **Monitoring & Alerts**
- `GET /api/v1/monitoring/alerts` - Get alert rules
- `POST /api/v1/monitoring/alerts` - Create alert rule
- `POST /api/v1/monitoring/test-notification` - Test notifications

### **Reports & Export**
- `POST /api/v1/reports/generate-pdf` - Generate PDF reports
- `GET /api/v1/reports/export/{format}` - Export data (CSV/JSON)

---

## ðŸ”§ Service Management

### Check Running Services
```bash
# Use our custom script to check PIDs
./scripts/pids.sh

# Or manually check specific ports
lsof -i :8000  # Backend
lsof -i :5173  # Frontend 
lsof -i :11434 # Ollama

# Check all related processes
ps aux | grep -E "(uvicorn|npm|ollama)" | grep -v grep
```

### Stop Services
```bash
# Stop background processes
pkill -f "uvicorn"
pkill -f "npm run dev"

# Or use job control if running in foreground
# Ctrl+C in each terminal
```

### Restart Services
```bash
# Quick restart - use the dev script
./scripts/dev.sh

# Or restart manually:
# 1. Kill existing processes
pkill -f "uvicorn"
pkill -f "npm run dev"

# 2. Start backend (from project root)
source .venv/bin/activate
export PYTHONPATH="$PWD/agentic-stock-research"
python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload &

# 3. Start frontend
cd agentic-stock-research/frontend && npm run dev &
```

---

## ðŸ“‹ API Usage

### Stock Analysis
```bash
# Analyze US stocks
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"tickers": ["AAPL"], "country": "United States"}'

# Analyze Indian stocks  
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"tickers": ["JIOFIN"], "country": "India"}'
```

### AI Chat
```bash
# Chat with AI about stocks
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What is the current price of AAPL?"}'
```

### Supported Countries
```bash
# Get list of supported countries
curl http://localhost:8000/countries
```

### Multiâ€‘Ticker Analysis (Comparative View)
```bash
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"tickers": ["AAPL", "MSFT", "GOOGL"], "country": "United States"}' \
  | jq '{summary: .comparative_analysis.summary, recommendations: .comparative_analysis.recommendations}'
```

---

## ðŸ†• Enhanced Features

### New Analysis Modules
- **ðŸ¢ Peer Analysis**: Competitor benchmarking and relative positioning
- **ðŸ“Š Analyst Recommendations**: Consensus price targets and sentiment
- **ðŸ“ˆ Growth Prospects**: Multi-timeline growth projections (1Y/3Y/5Y+)
- **ðŸ’° Enhanced Valuation**: DCF, DDM, Comparables, Sum-of-Parts models
- **ðŸ§  AI-Powered Synthesis**: LLM-driven investment recommendations

### New Capabilities (2025)
- **ðŸ“ˆ Multiâ€‘Ticker Comparative Analysis**: Parallel synthesis for multiple tickers with rankings and portfolio suggestions
- **ðŸ§® Adaptive Scoring**: Sector/regimeâ€‘aware weights with confidence aggregation and explainability
- **ðŸ”Ž Explainability**: Componentâ€‘level contributions and perâ€‘metric rationale included in decisions
- **ðŸ’± Currency Normalization**: Crossâ€‘market financials converted via live FX rates for applesâ€‘toâ€‘apples comparison
- **ðŸŒ Data Federation (Optional)**: Multiâ€‘source reconciliation (Yahoo Finance + optional AlphaVantage/Polygon) with outlier handling
- **âš¡ Realâ€‘Time (Optional)**: WebSocket/polling streams, market event triggers, and incremental reâ€‘analysis

### International Support
- **ðŸ‡ºðŸ‡¸ US Markets**: NYSE, NASDAQ
- **ðŸ‡®ðŸ‡³ Indian Markets**: NSE (.NS), BSE (.BO)
- **ðŸ’± Multi-Currency**: Automatic currency detection and formatting

---

## ðŸ› Troubleshooting

### Backend Issues
```bash
# Check Python environment (should point to .venv/bin/python3)
which python3

# Test imports (from project root)
source .venv/bin/activate
export PYTHONPATH="$PWD/agentic-stock-research"
python3 -c "from app.main import app; print('âœ… Backend imports OK')"

# Check Ollama connection
curl http://localhost:11434/api/tags

# Manual backend start with verbose logging
python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --log-level debug
```

### Frontend Issues
```bash
# Clear npm cache and reinstall
cd agentic-stock-research/frontend
rm -rf node_modules package-lock.json
npm cache clean --force
npm install

# Check environment variables
cat .env

# Build and preview production version
npm run build
npm run preview
```

### Ollama Issues
```bash
# Restart Ollama service
ollama serve

# Pull model again if corrupted
ollama pull gemma3:4b

# List available models
ollama list

# Check Ollama logs
tail -f ~/.ollama/logs/server.log
```

### Common Port Conflicts
```bash
# Find process using port 8000
lsof -ti :8000 | xargs kill -9

# Use alternative ports
# Backend: uvicorn ... --port 8001
# Frontend: npm run dev -- --port 5174
# Update VITE_API_BASE_URL accordingly
```

---

## ðŸ§ª Testing

### Backend Tests
```bash
# From project root
source .venv/bin/activate
export PYTHONPATH="$PWD/agentic-stock-research"

# Run all tests
pytest tests/ -v

# Run specific test files
pytest agentic-stock-research/tests/test_enhancements.py -v
```

### Frontend Tests
```bash
cd agentic-stock-research/frontend
npm run test
```

### Integration Tests
```bash
# Test complete workflow
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"tickers": ["AAPL"], "country": "United States"}' | jq '.reports[0].decision'
```

---

## ðŸ“Š Production Deployment

### Build Production Image
```bash
# Build optimized Docker image
docker build -t equisense-ai:latest .

# Run production container
docker run -p 8000:8000 \
  -e OLLAMA_MODEL=gemma3:4b \
  -e LANGFUSE_PUBLIC_KEY=your_key \
  equisense-ai:latest
```

### Environment Variables
Create `.env` files for configuration:

**Backend** (`agentic-stock-research/.env`):
```env
# Core LLM Settings
OLLAMA_MODEL=gemma3:4b
LLM_NAME=gemma3:4b
LLM_HOST=localhost
LLM_PORT=11434

# Observability (Optional)
LANGFUSE_PUBLIC_KEY=your_public_key
LANGFUSE_SECRET_KEY=your_secret_key
LANGFUSE_HOST=http://localhost:3100

# API Keys (Optional)
YOUTUBE_API_KEY=your_youtube_key
ALPHAVANTAGE_API_KEY=your_alpha_vantage_key
POLYGON_API_KEY=your_polygon_key
```

**Frontend** (`agentic-stock-research/frontend/.env`):
```env
VITE_API_BASE_URL=http://localhost:8000
```

---

## ðŸ“ˆ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontendâ”‚    â”‚  FastAPI Backend â”‚    â”‚   Ollama LLM    â”‚
â”‚   (Port 5173)   â”‚â—„â”€â”€â–ºâ”‚   (Port 8000)    â”‚â—„â”€â”€â–ºâ”‚  (Port 11434)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   LangGraph      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚   Workflow       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Financial APIs  â”‚
                        â”‚ (Yahoo Finance)  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/new-analysis-node`
3. Make changes and test thoroughly
4. Submit a pull request

---

## ðŸ“„ License

This project is licensed under the MIT License. See LICENSE file for details.

---

## ðŸ†˜ Support

For issues and questions:
1. Check the troubleshooting section above
2. Search existing GitHub issues
3. Create a new issue with detailed error logs and system info

**System Requirements:**
- macOS/Linux (Windows with WSL2)
- Python 3.11+, Node.js 18+
- 8GB+ RAM (for Ollama models)
- 10GB+ free disk space